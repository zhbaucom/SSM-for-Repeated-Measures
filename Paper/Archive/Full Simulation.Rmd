---
output: pdf_document
header-includes:
- \usepackage{booktabs}
- \usepackage{longtable}
- \usepackage{array}
- \usepackage{multirow}
- \usepackage{wrapfig}
- \usepackage{float}
- \usepackage{colortbl}
- \usepackage{pdflscape}
- \usepackage{tabu}
- \usepackage{threeparttable}
- \usepackage{threeparttablex}
- \usepackage[normalem]{ulem}
- \usepackage{makecell}
- \usepackage{xcolor}
---


```{r setup, include=FALSE}
library(gridExtra)
library(lme4)
library(tidyverse)
library(knitr)
library(kableExtra)
library(latex2exp)

source("functions/BayesKalmUneq2.R") #Holds the Bayesian Kalman Regression
source("functions/ss.simp.sim.R") #To simulate the data

fct_case_when <- function(...) {
  args <- as.list(match.call())
  levels <- sapply(args[-1], function(f) f[[3]])  # extract RHS of formula
  levels <- levels[!is.na(levels)]
  factor(dplyr::case_when(...), levels=levels)
}
knitr::opts_chunk$set(echo = FALSE)


```


# Simulation Results

## Fully Simulated Data


To assess parameter estimate accuracy of the state space model we ran a simulation study comparing the SSM to an LMEM and an LMEM with an AR(1) variance structure. Data was simulated to emulate effect estimates observed from the NACC data set. Longitudinal neuropsychological scores were simulated for 100 subjects. The number of observation times were varied between subjects with the possibility of unequal time between visits. Each subject had 2 to 6 observed scores at possible observation times 0 through 5. Each subject had 5 randomly generated baseline by time interaction covariates with linear effects: -0.402, 0.000, 0.144, -0.012, and -0.042. These are the same linear effects estimates from the model predicting the animals score from sex, education, race, baseline age, and APOE status. Under each simulation scenario we used the data to estimate the linear effects using a LMEM with random intercept, a LMEM with an AR(1) variance structure, the full likelihood state space model, partitioned state space models with 2, 4, and 10 groups, and the bayesian state space model.

Each simulation scenario model had the same underlying constant linear effect $\tilde x_t$:



\begin{equation*}
\tilde x_{t} =  x_{1t} (-0.402) +  x_{2t} (0.000) + x_{3t} (0.144) + x_{4t} (-0.012) +  x_{5t} (-0.040)
\end{equation*}


We simulated data from multiple state space models of the form,


\begin{equation*}
\begin{aligned}
y_t =  \alpha_t + \tilde x_t + \varepsilon_t, \ \ \ \varepsilon_t \sim N(0,\sigma^2_\varepsilon I_n)\\
\alpha_t =  \alpha_{t-1} + \eta_t, \ \ \ \eta_t \sim N(0,\sigma^2_\eta I_n)\\
\end{aligned}
\end{equation*}

The variance parameters $\sigma^2_\varepsilon$ and $\sigma^2_\eta$ were altered in varying combinations. Recall, when $\sigma^2_\eta = 0$, the model is equivalent to a LMEM with a random intercept. 

Lastly, The data was simulated from a LMEM with an AR(1) variance structure on the errors with $\rho = 0.1, 0.5, \text{and } 0.9$.


\begin{equation*}
\begin{aligned}
y_t &=  b_0 + \tilde x_t + \epsilon_t, \ \ \ b_0 \sim N(0, I_n)\\ 
\epsilon_t &= \rho \ \epsilon_{t-1} + e_t,\ \ \ e_t \sim N(0, I_n)
\end{aligned}
\end{equation*}

Each simulation scenario was repeated 1000 times. The main metrics of interest are 95% confidence interval coverage, bias evaluation, and confidence interval length as a stand in for estimate variance. We chose confidence interval length because the Bayesian state space model uses an empirical pseudo 95% confidence interval from the posterior draws instead of a typical parametric effect estimate variance.

## Fully Simulated Data Results

All methods show unbiasedness under each simulation scenario. Of the state space models the Bayesian estimation process seems to have the smallest variability in effect estimates and also closely rivals that of the LMEMs. The partitioned state space model with k = 10 groups shows high estimate volatility, however, k = 2 and 4 groups are reasonable when compared to the full data model. When there is no autocorrelation in the data ($\sigma^2_\eta = 0$), the state space models tend to over estimate the 95% confidence intervals by 2-3%. This is not surprising as the SSM models assume $\sigma^2_\eta > 0$ which increases the variability in possible parameter estimate values. However, when we increase $\sigma^2_\eta$ the coverage of the LMEM decreases where all the SSM models stay near 95% coverage. The Bayesian method stands out in the state space model simulation scenarios as it maintains 95% coverage, is unbiased, shows the smallest estimate variability, and has the smallest confidence intervals.

When the simulation scenario has AR(1) errors, as $\rho$ increases, coverage decreases for the state space models. Model assumption issues are quickly apparent in the Bayesian posterior draws. Figure ??? shows a plot of parameter estimate draws from a SSM and AR(1). The SSM shows good mixture, whereas the AR(1) shows highly autocorrelated draws in a non-convergent chain. The sensitivity to correct model specification in the Bayesian method can be used  as a post-hoc test for adequate model usage.


**as likelihood estimation and posterior distribution draws come from distributions truncated at 0. Future work could include estimating the log-likelihood of $log(\sigma^2_\eta)$ for the likelihood version and putting a joint distribution prior on the variance parameter $\sigma^2_\eta$.**



```{r}
set.seed(24)
#Fixed Params
SimNum <- 1000

n <- 100 #Number of subjects
B <- readRDS("NACC/B.RDS") #Beta Vector
p <- length(B) #Number of Betas



u0.true <- 0 #True mean of mu_0
P0.true <- 1 #True variance of mu_0

t <- 6
#####Bayesian Kalman Filter
#Beta ~ N(Beta.Initial, sigma2.beta)
Beta.Initial <- 0
# Beta.Initial <- B
sigma2.beta <- 10
#sigma2.eta ~ IG(a0/2, b0/2)
a0 <- .01
b0 <- .01
#sigma2.ps ~ IG(c0/2, d0/2)
c0 <- .01
d0 <- .01
#mu0 ~ N(u0, P0)
u0 <- 0
P0 <- 10
########### Select Iterations and Burn ########### 
Its <- 3000
Burn <- ceiling(Its/2)


rhoS = list(order = c(1, 0, 0), ar = 0.9, sd = 1)
simXfun <- runif
X <- matrix(simXfun(p*n, 0, 20), n, p)

XY <- lapply(1:t, function(x){
    xout <- cbind(1:n, x, (x*X) %*% B, x*X)
    colnames(xout) <- c("id","time", "XB", paste("X", 1:p, sep = ""))
    xout
  } ) %>%
    do.call("rbind", .) %>%
    as_tibble() %>%
    group_by(id) %>%
    mutate(error = arima.sim(n = n(), model = rhoS)) %>%
    mutate(y = XB + error) %>%
    select(-XB, -error) %>%
    ungroup(id) %>%
    arrange(id, time)

XY <- XY %>%
  group_by(id) %>%
  mutate(Keep = c(TRUE, 2:n() %in% sample(2:n(), sample(1:(length(id)-1), 1)))) %>%
  ungroup(id) %>%
  filter(Keep == TRUE) %>%
  arrange(id, time)

############FORMAT DATA FOR REGULAR KALMAN FILTER
y.long <- XY$y
X.long <- as.matrix(XY[,paste("X", 1:p, sep = "")])
id <- XY$id
time <- XY$time

Beta.Initial <- coef(lm(y.long ~ X.long - 1))

bkout <- BayesKalm.Uneq(
  y.long = y.long, X.long = X.long, id = id, time = time,
  Burn = Burn, Its = Its, 
  Beta.Initial = Beta.Initial, sigma2.beta = sigma2.beta, 
  u0 = u0, P0 = P0, 
  a0 = a0, b0 = b0, 
  c0 = c0, d0 = d0,
  silence = TRUE
)


p1 <- bkout$Beta %>%
  t() %>%
  data.frame() %>%
  set_names(paste("B", 1:length(B), sep = "")) %>%
  mutate(ind = 1:nrow(.)) %>%
  gather("Beta", "Value", -ind) %>%
  mutate(Z = B[as.numeric(substr(Beta, 2, nchar(Beta)))]) %>%
  filter(Beta == "B1", ind > Burn) %>%
  ggplot(aes(x = ind, y = Value, color = Beta)) + 
  geom_point(shape = 21) + 
  geom_hline(aes(yintercept = Z), col = "red") +
  xlab("Gibb's Sample iteration") +
  theme(legend.position = "none")
```


```{r}
colnames(X) <- paste("X", 1:ncol(X), sep = "")
ytot <- ss.simp.sim(X, B, t = t, sigma2.eps = 3, sigma2.eta = 1, u0 = u0.true, P0 = P0.true) #Creates a simulated y

y <- ytot

colnames(y) <- paste("y", 1:ncol(y), sep = "")

XY1 <- cbind(id = 1:n, y, X)

XYs <- XY1 %>%
  data.frame() %>%
  gather("time", "y", colnames(.)[grepl("y", colnames(.))]) %>%
  mutate(time = as.numeric(substr(time, 2, nchar(time)))) 

XYs[grepl("X", colnames(XYs))] <- XYs[grepl("X", colnames(XYs))] * XYs$time


XY <- XYs %>%
  filter(!is.na(y)) %>%
  arrange(id, time) 
  
  ############FORMAT DATA FOR REGULAR KALMAN FILTER
y.long <- XY$y
X.long <- as.matrix(XY[,paste("X", 1:p, sep = "")])
id <- XY$id
time <- XY$time

Beta.Initial <- coef(lm(y.long ~ X.long - 1))

bkout <- BayesKalm.Uneq(
  y.long = y.long, X.long = X.long, id = id, time = time,
  Burn = Burn, Its = Its, 
  Beta.Initial = Beta.Initial, sigma2.beta = sigma2.beta, 
  u0 = u0, P0 = P0, 
  a0 = a0, b0 = b0, 
  c0 = c0, d0 = d0,
  silence = TRUE
)


p2 <- bkout$Beta %>%
  t() %>%
  data.frame() %>%
  set_names(paste("B", 1:length(B), sep = "")) %>%
  mutate(ind = 1:nrow(.)) %>%
  gather("Beta", "Value", -ind) %>%
  mutate(Z = B[as.numeric(substr(Beta, 2, nchar(Beta)))]) %>%
  filter(Beta == "B1", ind > Burn) %>%
  ggplot(aes(x = ind, y = Value, color = Beta)) + 
  geom_point(shape = 21) + 
  geom_hline(aes(yintercept = Z), col = "red") +
  xlab("Gibb's Sample iteration") +
  theme(legend.position = "none")
```

```{r, fig.height=3}
grid.arrange(p1, p2, ncol = 2)
```



```{r}
SimPrefix <- "ItoutNACC4 "

flist <- list.files("Simulations/SimOutReform")
flist <- flist[grepl(SimPrefix,flist)]
B <- readRDS("NACC/B.RDS")
SimList <- map(flist, ~readRDS(paste("Simulations/SimOutReform/",.x, sep = "")))
# map(Itout, "Fails")
names(SimList) <- flist

```

```{r, warning = FALSE}

x <- flist[1]


Coverage <- sapply(flist, function(x){
  Itout <- SimList[[x]] 
  Coverage <- apply(Itout$UCL >= B & Itout$LCL <= B, 1:2, mean, na.rm = TRUE)[1,] 

  Vars <- x %>% 
    gsub(SimPrefix, "", .) %>%
    gsub(".RDS", "", .) %>%
    str_split(" ") %>%
    .[[1]] %>%
    gsub("_", ".", .) %>%
    as.numeric()
    c(round(Vars, 1), round(Coverage, 3))
  
}) %>% 
  t()



colnames(Coverage) <- c("sigeps", "sigeta","LME", "AR(1)", "SSM", "Bayes", "Part2", "Part4", "Part10") 


Coverage[,c("sigeps", "sigeta","LME", "AR(1)", "SSM", "Part2", "Part4", "Part10", "Bayes")] %>%
  data.frame() %>%
  rownames_to_column("SimScen") %>%
  mutate(sigeps = as.character(sigeps), sigeta = as.character(sigeta)) %>%
  mutate(
    sigeps = case_when(
      is.na(sigeps) ~ "1",
      TRUE ~ sigeps
    ),
    sigeta = case_when(
        is.na(sigeta) & grepl("Small", SimScen) ~ "$\\rho = 0.1$",
        is.na(sigeta) & grepl("Medium", SimScen) ~ "$\\rho = 0.5$",
        is.na(sigeta) & grepl("Large", SimScen) ~ "$\\rho = 0.9$",
      TRUE ~ sigeta
    )
  ) %>%
  select(-SimScen) %>%
  kable(row.names = FALSE, escape = FALSE,
        col.names = c("$\\sigma^2_\\varepsilon$", "$\\sigma^2_\\eta$","LME", "AR(1)", "SSM", "Bayes", "Part2", "Part4", "Part10")) %>%
  add_header_above(c("Variance\nParameters" = 2, "Traditional\nMethods" = 2,"State Space Methods" = 5)) %>%
  kable_styling()
```


```{r}


i <- 1

  
outb <- lapply(flist, function(x){
 Vars <- x %>% 
  gsub("ItoutPaper ", "", .) %>%
  gsub(".RDS", "", .) %>%
  str_split(" ") %>%
  .[[1]] %>%
  gsub("_", ".", .)

  Itout <- SimList[[x]]
  Bias <- Itout$Estimate - B

  vb <- lapply(1:dim(Bias)[1], function(x)t(Bias[x,,]))
  VarBias <- data.frame(do.call("rbind", vb))
  
  VarBias$Variable <- sort(rep(paste("B", seq_along(B), sep = ""), dim(Bias)[3]))
  
  
  
  colnames(VarBias) <-  c("LME", "LME AR(1)", "SS Orig", "SS Bayes", "SS Part 2", "SS Part 4", "SS Part 10",  "Variable") 
  
  VarBias %>%
    data.frame() %>%
    gather("Method", "Bias", `LME`:`SS.Part.10`) %>%
    mutate(Method = fct_case_when(
      Method == "LME" ~ "LME",
      Method == "LME.AR.1." ~ "LME AR(1)",
      Method == "SS.Orig" ~ "SS Original",
      Method == "SS.Bayes" ~ "SS Bayes",
      Method == "SS.Part.2" ~ "SS Part k = 2",
      Method == "SS.Part.4" ~ "SS Part k = 4",
      Method == "SS.Part.10" ~ "SS Part k = 10"
    ),
    sig2eps = Vars[2], sig2eta = Vars[3], Vars = paste("$\\sigma^2_{\\epsilon} = ", Vars[2], ", \ \\sigma^2_{\\eta} = ", Vars[3], "$", sep = ""),
    ) %>%
    mutate(
      Vars = case_when(
        grepl("Small", x) ~ "$\\rho = 0.1$",
        grepl("Medium", x) ~ "$\\rho = 0.5$",
        grepl("Large", x) ~ "$\\rho = 0.9$",
        TRUE ~ Vars
      )
    ) %>%
    # mutate(Vars = TeX(Vars)) %>%
    filter(Variable == paste("B", i, sep = ""))

  }) %>%
  do.call("rbind", .) %>%
  mutate(Method = factor(Method, levels = c("LME", "LME AR(1)", "SS Original", "SS Part k = 2", "SS Part k = 4", "SS Part k = 10", "SS Bayes"))) %>%
  mutate(Vars = as.factor(Vars)) %>%
  group_by(Vars, Method) %>%
  filter(!is.na(Bias)) %>%
  filter(Bias < quantile(Bias, .90) & Bias > quantile(Bias, .10)) %>%
  ungroup(Vars, Method)

levels(outb$Vars) <- TeX(levels(outb$Vars))
outb$Vars <- factor(outb$Vars, levels = levels(outb$Vars)[c(
  which(!grepl("rho", levels(outb$Vars))),
  which(grepl("rho", levels(outb$Vars)))
)])


pbias <- ggplot(outb, aes(x = Method, y = Bias, fill = Method)) + 
  geom_violin() + 
  stat_summary(fun=median, geom="point", shape=18, size=5) +
  geom_hline(yintercept = 0 , color = "red") +
  facet_wrap((Vars) ~ ., scales = "free_y",
  labeller=label_parsed)+
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank())
print(pbias)
```


```{r}



  

  outci <- lapply(flist, function(x){
    Vars <- x %>% 
      gsub("ItoutPaper ", "", .) %>%
      gsub(".RDS", "", .) %>%
      str_split(" ") %>%
      .[[1]] %>%
      gsub("_", ".", .)
  
    Itout <- SimList[[x]]
    CIlen <- Itout$UCL -Itout$LCL
    # CIlen1 <- t(CIlen[1,,])
    # CIlen2 <- t(CIlen[2,,])
    # CIlen3 <- t(CIlen[3,,])
    # CIlenTot <- data.frame(rbind(CIlen1, CIlen2, CIlen3))
    cilen <- lapply(1:dim(CIlen)[1], function(x)t(CIlen[x,,]))
    CIlenTot <- data.frame(do.call("rbind", cilen))
    
    
  
  CIlenTot$Variable <- sort(rep(paste("B", seq_along(B), sep = ""), dim(CIlen)[3]))
  
  
  
  colnames(CIlenTot) <-  c("LME", "LME AR(1)", "SS Orig", "SS Bayes", "SS Part 2", "SS Part 4", "SS Part 10",  "Variable") 
  
  outci <- CIlenTot %>%
    data.frame() %>%
    gather("Method", "CI.Length", `LME`:`SS.Part.10`) %>%
    mutate(Method = fct_case_when(
      Method == "LME" ~ "LME",
      Method == "LME.AR.1." ~ "LME AR(1)",
      Method == "SS.Orig" ~ "SS Original",
      Method == "SS.Bayes" ~ "SS Bayes",
      Method == "SS.Part.2" ~ "SS Part k = 2",
      Method == "SS.Part.4" ~ "SS Part k = 4",
      Method == "SS.Part.10" ~ "SS Part k = 10"
    ),
      sig2eps = Vars[2], sig2eta = Vars[3], Vars = paste("$\\sigma^2_{\\epsilon} = ", Vars[2], ", \ \\sigma^2_{\\eta} = ", Vars[3], "$", sep = "")) %>%
      mutate(
        Vars = case_when(
          grepl("Small", x) ~ "$\\rho = 0.1$",
          grepl("Medium", x) ~ "$\\rho = 0.5$",
          grepl("Large", x) ~ "$\\rho = 0.9$",
          TRUE ~ Vars
        )
      ) %>%
    filter(Variable == paste("B",i, sep = ""))
  }) %>%
  do.call("rbind", .) %>%
  mutate(Method = factor(Method, levels = c("LME", "LME AR(1)", "SS Original", "SS Part k = 2", "SS Part k = 4", "SS Part k = 10", "SS Bayes")))%>%
  mutate(Vars = as.factor(Vars)) %>%
  group_by(Vars, Method) %>%
  filter(!is.na(CI.Length)) %>%
  filter(CI.Length < quantile(CI.Length, .90) & CI.Length > quantile(CI.Length, .10)) %>%
  ungroup(Vars, Method)

levels(outci$Vars) <- TeX(levels(outci$Vars))

outci$Vars <- factor(outci$Vars, levels = levels(outci$Vars)[c(
  which(!grepl("rho", levels(outci$Vars))),
  which(grepl("rho", levels(outci$Vars)))
)])

pci <- outci %>%
  # filter(!(Method %in% c("LME", "LME AR(1)"))) %>%
  ggplot(aes(x = Method, y = CI.Length, fill = Method)) + 
  geom_violin() + 
  stat_summary(fun=median, geom="point", shape=18, size=2) +
  facet_wrap((Vars) ~ ., scales = "free_y",
  labeller=label_parsed)+
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank())
print(pci)

```



























